{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read file \n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test.csv')\n",
    "df = pd.read_csv(\"ex_submit.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop Nan index and reset dataFrame's index\n",
    "df_train = df_train.dropna()\n",
    "df_train = df_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the len of this dataFrame\n",
    "columns = df_train.columns\n",
    "size_train = len(df_train[df_train.columns[0]])\n",
    "size_test = len(df_test[df_test.columns[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up storing data numpy array\n",
    "train_examples = np.zeros((size_train, 22))\n",
    "test_examples = np.zeros((size_test, 22))\n",
    "train_labels = np.zeros((size_train,))\n",
    "test_labels = np.ones((size_test,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transfrom date data\n",
    "for i in range(size_train):\n",
    "    s = df_train[columns[0]][i]\n",
    "    date1 = datetime.datetime.strptime(s, \"%Y-%m-%d\")\n",
    "    date2 = datetime.datetime.strptime(s.split(\"-\")[0]+\"-1-1\", \"%Y-%m-%d\")\n",
    "    train_examples[i][0] = (date1 - date2).days\n",
    "    del date1\n",
    "    del date2\n",
    "    del s\n",
    "\n",
    "for i in range(size_test):\n",
    "    s = df_test[df_test.columns[0]][i]\n",
    "    date1 = datetime.datetime.strptime(s, \"%Y-%m-%d\")\n",
    "    date2 = datetime.datetime.strptime(s.split(\"-\")[0]+\"-1-1\", \"%Y-%m-%d\")\n",
    "    test_examples[i][0] = (date1 - date2).days\n",
    "    del date1\n",
    "    del date2\n",
    "    del s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put number data directly into dataFrame\n",
    "n = 1\n",
    "for col in range(1, 15):\n",
    "    if col==7 or col==9:\n",
    "        continue\n",
    "    for i in range(size_train):\n",
    "        train_examples[i][n] = df_train[columns[col]][i]\n",
    "    n += 1\n",
    "\n",
    "n = 1\n",
    "for col in range(1, 15):\n",
    "    if col==7 or col==9:\n",
    "        continue\n",
    "    for i in range(size_test):\n",
    "        test_examples[i][n] = df_test[columns[col]][i]\n",
    "    n += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn wind direction in to 4 columns\n",
    "for col in [7, 9]:\n",
    "    if col==7:\n",
    "        j = 13\n",
    "    elif col==9:\n",
    "        j = 17\n",
    "    dic = {\"W\":0,\"E\":1,\"N\":2,\"S\":3}\n",
    "    for i in range(size_train):\n",
    "        s = str(df_train[columns[col]][i])\n",
    "        if not s or s==\"\" or s=='nan':\n",
    "            s = \"WENS\"\n",
    "        for c in s:\n",
    "            train_examples[i][j+dic[c]] += 4/len(s)\n",
    "    \n",
    "    for i in range(size_test):\n",
    "        s = str(df_test[columns[col]][i])\n",
    "        if not s or s==\"\" or s=='nan':\n",
    "            s = \"WENS\"\n",
    "        for c in s:\n",
    "            test_examples[i][j+dic[c]] += 4/len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transfrom non-number data into number data\n",
    "for i in range(size_train):\n",
    "    if df_train[columns[15]][i]==\"Yes\":\n",
    "        train_examples[i][21] = 1\n",
    "    elif df_train[columns[15]][i]==\"No\":\n",
    "        train_examples[i][21] = 0\n",
    "\n",
    "for i in range(size_test):\n",
    "    if df_test[columns[15]][i]==\"Yes\":\n",
    "        test_examples[i][21] = 1\n",
    "    elif df_test[columns[15]][i]==\"No\":\n",
    "        test_examples[i][21] = 0\n",
    "\n",
    "for i in range(size_train):\n",
    "    if df_train[columns[16]][i]==\"Yes\":\n",
    "        train_labels[i] = 1\n",
    "    elif df_train[columns[16]][i]==\"No\":\n",
    "        train_labels[i] = 0\n",
    "\n",
    "for i in range(size_train):\n",
    "    if df_train[columns[16]][i]==\"Yes\":\n",
    "        train_labels[i] = 1\n",
    "    elif df_train[columns[16]][i]==\"No\":\n",
    "        train_labels[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.182548794489093"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculate the threshold about which data would rain next day\n",
    "ratio = np.count_nonzero(train_labels == 1)/size_train\n",
    "ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-17 14:49:39.811829: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up keras model\n",
    "X_train, y_train, X_test = np.delete(train_examples, [0], 1), to_categorical(train_labels), np.delete(test_examples, [0], 1)\n",
    "\n",
    "keras_model = Sequential()\n",
    "keras_model.add(Dense(256, activation='relu', input_dim=21))\n",
    "keras_model.add(Dense(128, activation='relu'))\n",
    "keras_model.add(Dense(64, activation='relu'))\n",
    "keras_model.add(Dense(32, activation='relu'))\n",
    "keras_model.add(Dense(16, activation='relu'))\n",
    "keras_model.add(Dense(8, activation='relu'))\n",
    "keras_model.add(Dense(4, activation='relu'))\n",
    "keras_model.add(Dense(2, activation='softmax'))\n",
    "keras_model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.05), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "55/55 [==============================] - 1s 2ms/step - loss: 27.6942 - accuracy: 0.6873\n",
      "Epoch 2/1000\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.8194\n",
      "Epoch 3/1000\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.8206\n",
      "Epoch 4/1000\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4743 - accuracy: 0.8182\n",
      "Epoch 5/1000\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4763 - accuracy: 0.8169\n",
      "Epoch 6/1000\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.4722 - accuracy: 0.8195\n",
      "Epoch 7/1000\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.8174\n",
      "Epoch 8/1000\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.8169\n",
      "Epoch 9/1000\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4685 - accuracy: 0.8226\n",
      "Epoch 10/1000\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4635 - accuracy: 0.8254\n",
      "Epoch 11/1000\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.8234\n",
      "Epoch 12/1000\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.4727 - accuracy: 0.8194\n",
      "Epoch 13/1000\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.8179\n",
      "Epoch 14/1000\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.8146\n",
      "Epoch 15/1000\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.8157\n",
      "Epoch 16/1000\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.4768 - accuracy: 0.8169\n",
      "Epoch 17/1000\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.8127\n",
      "Epoch 18/1000\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.4719 - accuracy: 0.8199\n",
      "Epoch 19/1000\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.4813 - accuracy: 0.8134\n",
      "Epoch 20/1000\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.8200\n",
      "Epoch 21/1000\n",
      "55/55 [==============================] - 0s 6ms/step - loss: 0.4750 - accuracy: 0.8178\n",
      "Epoch 22/1000\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.8197\n",
      "Epoch 23/1000\n",
      "55/55 [==============================] - 0s 3ms/step - loss: 0.4715 - accuracy: 0.8206\n",
      "Epoch 24/1000\n",
      "55/55 [==============================] - 0s 4ms/step - loss: 0.4789 - accuracy: 0.8157\n",
      "Epoch 25/1000\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.8208\n",
      "Epoch 26/1000\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.4751 - accuracy: 0.8180\n",
      "Epoch 27/1000\n",
      "55/55 [==============================] - 0s 5ms/step - loss: 0.4795 - accuracy: 0.8147\n",
      "Epoch 28/1000\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.8138\n",
      "Epoch 29/1000\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.8189\n",
      "Epoch 30/1000\n",
      "55/55 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.8155\n",
      "Epoch 31/1000\n",
      "53/55 [===========================>..] - ETA: 0s - loss: 0.4766 - accuracy: 0.8170"
     ]
    }
   ],
   "source": [
    "#run keras model\n",
    "keras_model.fit(x=X_train, y=y_train, batch_size = 128, epochs=1000, shuffle=True, verbose=1)\n",
    "keras_prob = keras_model.predict(X_test, verbose=False)\n",
    "keras_prediction = np.array([1 if i[1]>ratio else 0 for i in keras_prob])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6505/1007258010.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"ans\"][i] = str(int(keras_prediction[i]))\n",
      "/tmp/ipykernel_6505/1007258010.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"id\"][i] = str(float(i))\n"
     ]
    }
   ],
   "source": [
    "#store result to keras.csv\n",
    "for i in range(size_test):\n",
    "    df[\"ans\"][i] = str(int(keras_prediction[i]))\n",
    "    df[\"id\"][i] = str(float(i))\n",
    "\n",
    "df.to_csv('keras.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored on calling ctypes callback function: <function _ThreadpoolInfo._find_modules_with_dl_iterate_phdr.<locals>.match_module_callback at 0x7f0df63c5280>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/wei/anaconda3/envs/data/lib/python3.8/site-packages/threadpoolctl.py\", line 400, in match_module_callback\n",
      "    self._make_module_from_path(filepath)\n",
      "  File \"/home/wei/anaconda3/envs/data/lib/python3.8/site-packages/threadpoolctl.py\", line 515, in _make_module_from_path\n",
      "    module = module_class(filepath, prefix, user_api, internal_api)\n",
      "  File \"/home/wei/anaconda3/envs/data/lib/python3.8/site-packages/threadpoolctl.py\", line 606, in __init__\n",
      "    self.version = self.get_version()\n",
      "  File \"/home/wei/anaconda3/envs/data/lib/python3.8/site-packages/threadpoolctl.py\", line 646, in get_version\n",
      "    config = get_config().split()\n",
      "AttributeError: 'NoneType' object has no attribute 'split'\n"
     ]
    }
   ],
   "source": [
    "#set up KNN model\n",
    "X_train, y_train, X_test = np.delete(train_examples, [0], 1), train_labels, np.delete(test_examples, [0], 1)\n",
    "\n",
    "KNN_model = KNeighborsClassifier(n_neighbors=50, weights=\"distance\")\n",
    "KNN_model.fit(X_train, y_train)\n",
    "KNN_prob = KNN_model.predict_proba(X_test)\n",
    "KNN_prediction = np.array([1 if i[1]>ratio else 0 for i in KNN_prob])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save result to KNN.csv\n",
    "for i in range(size_test):\n",
    "    df[\"ans\"][i] = str(int(KNN_prediction[i]))\n",
    "    df[\"id\"][i] = str(float(i))\n",
    "df.to_csv('KNN.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from rgf.sklearn import RGFClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wei/anaconda3/envs/data/lib/python3.8/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:10:11] WARNING: /tmp/abs_40obctay9q/croots/recipe/xgboost-split_1659548945886/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "#set up xgb model\n",
    "X_train, y_train, X_test = np.delete(train_examples, [0], 1), train_labels, np.delete(test_examples, [0], 1)\n",
    "clf = xgb.XGBClassifier()\n",
    "xgb_reg = xgb.XGBClassifier(learning_rate = 0.01, max_depth = 10, alpha = 12, n_estimators = 80)\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "xgb_prob = xgb_reg.predict_proba(X_test)\n",
    "xgb_prediction = np.array([1 if i[1]>ratio else 0 for i in xgb_prob])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save result to xgb.csv\n",
    "for i in range(size_test):\n",
    "    df[\"ans\"][i] = str(int(xgb_prediction[i]))\n",
    "    df[\"id\"][i] = str(float(i))\n",
    "df.to_csv('xgb.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rgf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up rgf model\n",
    "X_train, y_train, X_test = np.delete(train_examples, [0], 1), train_labels, np.delete(test_examples, [0], 1)\n",
    "\n",
    "rgf = RGFClassifier(max_leaf=2000, algorithm=\"RGF_Sib\", test_interval=300, loss=\"Log\", verbose=False)\n",
    "rgf.fit(X_train, y_train)\n",
    "rgf_prob = rgf.predict_proba(X_test)\n",
    "rgf_prediction = np.array([1 if i[1]>ratio else 0 for i in rgf_prob])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save result to rgf.csv\n",
    "for i in range(size_test):\n",
    "    df[\"ans\"][i] = str(int(rgf_prediction[i]))\n",
    "    df[\"id\"][i] = str(float(i))\n",
    "df.to_csv('rgf.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mix result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up every prediction weight and mix them according to it\n",
    "prediction = [keras_prediction, KNN_prediction, xgb_prediction, rgf_prediction]\n",
    "prob = [keras_prob, KNN_prob, xgb_prob, rgf_prob]\n",
    "weight = [1, 5, 1, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction x weight to output outcome\n",
    "pop_norm = np.array([0.0 for i in range(size_test)])\n",
    "for i in range(4):\n",
    "    for j in range(size_test):\n",
    "        pop_norm[j] += prediction[i][j] * weight[i]\n",
    "pop_norm = np.array([1 if pop_norm[i] > 4 else 0 for i in range(size_test)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(size_test):\n",
    "    df[\"ans\"][i] = str(int(pop_norm[i]))\n",
    "    df[\"id\"][i] = str(float(i))\n",
    "df.to_csv('mix.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('data')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "402858f03a0beb5ed5133107f11f6abe5a451bdd2b12f53c17b0bf70dac3a0af"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
